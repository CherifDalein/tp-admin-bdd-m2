# TP â€” InfluxDB â†” Telegraf â†” Kafka

## ğŸ¯ Objectifs

Ce TP a pour but de mettre en place un pipeline **End-to-End (E2E)** permettant dâ€™observer le flux complet de donnÃ©es entre **InfluxDB**, **Telegraf**, **Kafka** et du **code Python**.
Lâ€™objectif est de comprendre comment ces outils interagissent dans une architecture distribuÃ©e et dâ€™observer le flux de messages via **Kafdrop**.

---

## Partie 1 â€” Prise en main

### 1ï¸ DÃ©marrage des services

La commande :

```bash
docker compose up
```

lance lâ€™ensemble des conteneurs dÃ©finis dans le fichier `docker-compose.yml`.
Chaque service se met en route selon sa configuration. Certains restent actifs en continu, dâ€™autres exÃ©cutent une tÃ¢che ponctuelle avant de sâ€™arrÃªter.

---

### 2ï¸ Observation des logs

* **InfluxDB** : initialise lâ€™organisation `myorg`, le bucket `weather` et crÃ©e un utilisateur admin avec un token (`mytoken`).
* **Kafka1 / Kafka2 / Kafka3** : forment un cluster Kafka avec quorum, affichent la synchronisation et dÃ©marrent le serveur (`Kafka Server started`).
* **Telegraf** : dÃ©marre et se connecte Ã  Kafka pour produire des mÃ©triques.
* **Init-topic**, **init-alert**, etc. : exÃ©cutent leurs commandes puis sâ€™arrÃªtent aprÃ¨s lâ€™initialisation.

---

### 3ï¸ Conteneurs exÃ©cutÃ©s durablement

| Conteneur                          | Fonction principale                                  |
| ---------------------------------- | ---------------------------------------------------- |
| **influxdb**                       | Base de donnÃ©es time-series                          |
| **kafka1**, **kafka2**, **kafka3** | Brokers Kafka (cluster distribuÃ©)                    |
| **telegraf**                       | Agent de collecte et dâ€™envoi de donnÃ©es              |
| **kafdrop**                        | Interface Web pour visualiser les topics et messages |

Ces conteneurs restent actifs pour assurer la persistance et la circulation des donnÃ©es.

---

### 4ï¸ Conteneurs temporaires

| Conteneur                                | Fonction                                                            |
| ---------------------------------------- | ------------------------------------------------------------------- |
| **init-topic** / **init-topic-telegraf** | CrÃ©ent les topics Kafka nÃ©cessaires (`weather`, `weather-telegraf`) |
| **init-alert**                           | Configure des alertes dans InfluxDB                                 |
| **inject**                               | InsÃ¨re des donnÃ©es simulÃ©es dans InfluxDB                           |
| **producer**                             | Publie les donnÃ©es dâ€™InfluxDB dans Kafka                            |

Ils sâ€™exÃ©cutent rapidement, effectuent leur tÃ¢che, puis sâ€™arrÃªtent.

---

##  Partie 2 â€” RÃ´le des diffÃ©rents conteneurs

### 5ï¸ RÃ´le de Telegraf

**Telegraf** est un agent qui collecte des donnÃ©es (mÃ©triques systÃ¨mes, capteurs ou bases) et les envoie vers dâ€™autres systÃ¨mes.
Dans ce TP, il :

* Lit des donnÃ©es mÃ©tÃ©o simulÃ©es,
* Les publie dans un **topic Kafka** nommÃ© `weather-telegraf`.

Il agit comme un **pont entre InfluxDB et Kafka**.

---

### 6ï¸ RÃ´le du conteneur `init-alert`

Ce conteneur configure des **alertes automatiques** dans InfluxDB via son API REST, par exemple pour signaler une valeur anormale dans les donnÃ©es (ex. tempÃ©rature trop Ã©levÃ©e).

---

### 7ï¸ RÃ´le du conteneur `init-topic`

Ce conteneur exÃ©cute la commande :

```bash
kafka-topics.sh --create --topic weather --partitions 4 --replication-factor 3
```

Il permet de crÃ©er le topic principal `weather` (4 partitions, rÃ©plication 3) au dÃ©marrage du cluster Kafka.

---

## Partie 3 â€” Ports mappÃ©s

### 8 Tableau rÃ©capitulatif des ports

| Service             | Port externe | Fonction                                  |
| ------------------- | ------------ | ----------------------------------------- |
| **InfluxDB**        | 8086         | API HTTP & interface web                  |
| **Kafka1**          | 9092         | Communication avec les clients Kafka      |
| **Kafdrop**         | 9000         | Interface web de gestion Kafka            |
| **Kafka2 / Kafka3** | 9092, 9093   | Communication inter-brokers et contrÃ´leur |

---

### 9ï¸ Kafdrop

* **Port exposÃ© :** `9000`
* **Fonction :** Interface web accessible sur `http://localhost:9000` permettant dâ€™explorer les topics, partitions et messages de Kafka.

---

### Kafka3

* **Ports utilisÃ©s :**

  * `9092` â†’ communication avec les producteurs/consommateurs
  * `9093` â†’ communication interne de contrÃ´le dans le cluster (Controller listener)

---

### 11 InfluxDB

* **Port 8086** : interface dâ€™administration et API REST.
  Accessible via `http://localhost:8086`.

---

## Partie 4 â€” DÃ©tails de configuration

### 12ï¸ Bucket InfluxDB

* **Nom :** `weather`
* **CrÃ©Ã© par :** le conteneur `influxdb` lui-mÃªme
* **MÃ©canisme :** via les variables dâ€™environnement :

```yaml
DOCKER_INFLUXDB_INIT_BUCKET=weather
```

---

### 13ï¸ SÃ©curitÃ© du dÃ©ploiement

Le dÃ©ploiement est fonctionnel mais **peu sÃ©curisÃ©** :

* Identifiants faibles : `admin / adminpass`
* Token (`mytoken`) exposÃ© en clair
* Pas de chiffrement TLS
* Port 8086 accessible publiquement

**AmÃ©liorations recommandÃ©es :**

* Utiliser des variables dâ€™environnement sÃ©curisÃ©es (fichiers `.env`)
* Ajouter TLS/HTTPS
* Restreindre les ports aux rÃ©seaux internes Docker
* Modifier les identifiants par dÃ©faut

---

### 14ï¸ Observation du topic dans Kafdrop

* **Topic :** `weather`
* **Partitions :** 4
* **Facteur de rÃ©plication :** 3
* **Auto-creation :** dÃ©sactivÃ©e, car le topic est crÃ©Ã© manuellement par `init-topic`.

---

### 15ï¸ VÃ©rification dans le docker-compose

On retrouve ces paramÃ¨tres dans la section :

```yaml
kafka-topics.sh --create --topic weather --partitions 4 --replication-factor 3
```

---

## Partie 5 â€” RÃ©silience de Kafka

### 16ï¸ ArrÃªt dâ€™un broker

Exemple :

```bash
docker stop kafka2
```

* Le cluster reste disponible grÃ¢ce Ã  la rÃ©plication.
* Certaines partitions peuvent devenir inaccessibles si leur leader Ã©tait sur `kafka2`.
* Pour corriger : redÃ©marrer le broker (`docker start kafka2`) ou reconfigurer la rÃ©partition des leaders.

---

### 17ï¸ RedÃ©marrage dâ€™un broker

Au redÃ©marrage, le broker rÃ©intÃ¨gre automatiquement le cluster et rÃ©cupÃ¨re les partitions manquantes.
Kafka rÃ©Ã©quilibre ensuite le leadership entre les brokers pour restaurer la haute disponibilitÃ©.

---

### 18ï¸ DiffÃ©rence entre `inject` et `producer`

| Service      | RÃ´le principal                                           |
| ------------ | -------------------------------------------------------- |
| **inject**   | GÃ©nÃ¨re des donnÃ©es et les envoie vers InfluxDB           |
| **producer** | RÃ©cupÃ¨re les donnÃ©es dâ€™InfluxDB et les publie dans Kafka |

Ainsi, `inject` alimente la base, et `producer` alimente le flux Kafka Ã  partir de cette base.

---

## Partie 6 â€” Aller plus loin

### 19ï¸ AmÃ©liorations possibles

* Ajouter **Grafana** pour la visualisation des donnÃ©es InfluxDB.
* SÃ©curiser la configuration (TLS, tokens, mots de passe).
* Mettre en place une **intÃ©gration continue** pour automatiser le dÃ©ploiement.
* Ajouter un **consumer Python** pour analyser les messages Kafka en temps rÃ©el.
* GÃ©rer la persistance et la sauvegarde automatique des volumes Docker.

---

### 20ï¸ Pourquoi encapsuler le code Python dans un conteneur ?

* Isolation complÃ¨te de lâ€™environnement (pas de conflit de dÃ©pendances).
* PortabilitÃ© entre machines (le mÃªme code fonctionne partout).
* IntÃ©gration facile dans le pipeline Docker Compose.
* ReproductibilitÃ© et cohÃ©rence lors du dÃ©ploiement.

---

### 21ï¸ Correction du schÃ©ma (schema.md)

Le schÃ©ma doit montrer clairement le flux complet de donnÃ©es :

```text
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   inject     â”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   InfluxDB   â”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚             â”‚
             â–¼             â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Producer â”‚     â”‚ Telegraf â”‚
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
           â”‚                 â”‚
           â–¼                 â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚     Kafka       â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Kafdrop   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Conclusion

Ce TP a permis de mettre en place et dâ€™observer un pipeline complet reliant **InfluxDB**, **Telegraf** et **Kafka**, en comprenant le rÃ´le de chaque conteneur et la rÃ©silience du cluster.
Il illustre parfaitement comment orchestrer des services interconnectÃ©s via Docker Compose pour gÃ©rer un flux de donnÃ©es temps rÃ©el.

