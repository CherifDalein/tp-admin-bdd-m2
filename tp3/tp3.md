export BROKER="localhost:9092"
export KSQLDB_URL="http://localhost:8088"


verification
curl -s "$KSQLDB_URL/info" | jq .
curl -s "$KSQLDB_URL/healthcheck"


1) 

docker exec -i kafka-1 \
  kafka-topics --bootstrap-server "$BROKER" \
  --create --topic temperatures --partitions 4 --replication-factor 1 --if-not-exists


la commande correcte est:

docker exec -i kafka-1 \
  kafka-topics --bootstrap-server "$BROKER" --describe --topic temperatures

taper la commande pour executer le script:

bash -lc 'python3 - <<'"'"'PY'"'"' | docker exec -i kafka-1 \
  kafka-console-producer --bootstrap-server '"$BROKER"' \
  --topic temperatures --property parse.key=true --property key.separator=:
import json,random,time,sys
villes=["Clermont-Ferrand","Lyon","Paris","Bordeaux","Nantes"]
for _ in range(200):
    v=random.choice(villes)
    rec={"ville":v,"t":round(random.uniform(5,35),1),"ts":int(time.time()*1000)}
    print(f"{v}:{json.dumps(rec)}"); sys.stdout.flush(); time.sleep(0.2)
PY'


puis aller sur ce lien http://localhost:9021/ pour verifier

Et tu v√©rifies :

le topic temperatures

la quantit√© de messages dans chaque partition

Tu devrais voir une r√©partition tr√®s in√©gale.
Pourquoi ? Parce que la cl√© d√©termine la partition via Murmur2.

Certaines villes tombent toujours sur la m√™me partition.

ou bien avec cette commande

docker exec -i kafka-1 \
  kafka-topics --bootstrap-server "$BROKER" --describe --topic temperatures


  APres le script est legerement modifi√©

  # Option - kafka-console-producer (cl√© via parse.key)
bash -lc 'python3 - <<'"'"'PY'"'"' | docker exec -i kafka-1 \
  kafka-console-producer --bootstrap-server '"$BROKER"' \
  --topic temperatures --property parse.key=true --property key.separator=:
import json,random,time,sys
villes=["Clermont-Ferrand","Lyon","Paris","Bordeaux","Montpellier"]
for _ in range(200):
    v=random.choice(villes)
    rec={"ville":v,"t":round(random.uniform(5,35),1),"ts":int(time.time()*1000)}
    print(f"{v}:{json.dumps(rec)}"); sys.stdout.flush(); time.sleep(0.2)
PY'


Question : qu‚Äôobservez-vous sur la r√©partition des messages ?

Ôëâ Tu observes que les messages sont r√©partis diff√©remment entre les partitions.

Plus pr√©cis√©ment :

Les villes communes (Lyon, Paris, etc.) restent dans les m√™mes partitions qu‚Äôavant, car leur hachage ne change pas.

Les messages de la nouvelle ville Montpellier tombent dans une autre partition, d√©termin√©e par sa valeur de hachage.

La r√©partition totale change, car Nantes et Montpellier n‚Äôont pas le m√™me hash ‚Üí donc pas la m√™me partition.

Ôìå La cl√© modifi√©e change la distribution globale.


Lien avec la fonction de hachage Murmur2

Kafka utilise :

üëâ Murmur2(key) % nombre_de_partitions
pour choisir la partition.

Donc :

chaque cl√© tombe toujours dans la m√™me partition, tant que le nombre de partitions ne change pas.

si tu remplaces une cl√© ‚Üí tu changes son hash ‚Üí donc sa partition.

c‚Äôest exactement pour √ßa que Nantes ‚â† Montpellier ‚Üí distribution diff√©rente.


Remarque: La r√©partition des messages d√©pend enti√®rement de la cl√©. Kafka utilise la fonction de hachage Murmur2 pour calculer la partition : partition = murmur2(key) % numPartitions.

Lorsque nous rempla√ßons "Nantes" par "Montpellier", les messages associ√©s √† cette cl√© sont envoy√©s dans une partition diff√©rente, car leur valeur de hachage est diff√©rente.

Les autres villes conservent la m√™me partition qu'avant car leur cl√© n‚Äôa pas chang√©.

2)

Pour se connecter √† ksqlDB, j‚Äôai utilis√© l‚Äôinterface Confluent Control Center disponible sur http://localhost:9021.
Dans le menu KSQLDB Cluster, j‚Äôai ouvert le moteur ksqlDB et ex√©cut√© la commande SHOW TOPICS;.
Cela m‚Äôa permis de visualiser les topics temperatures (4 partitions) et commandes.
L‚Äôoutil permet de v√©rifier facilement la pr√©sence des topics Kafka et leur configuration sans passer par le CLI.

voici ce que j'ai eu apres la commandes show topics;
{
  "@type": "kafka_topics",
  "statementText": "SHOW TOPICS;",
  "topics": [
    {
      "name": "commandes",
      "replicaInfo": [
        3
      ]
    },
    {
      "name": "temperatures",
      "replicaInfo": [
        1,
        1,
        1,
        1
      ]
    }
  ],
  "warnings": [

  ]
}





3) j'ai tap√© la commande juste apres avoir modifi√© un peu le code du producer 
while True:
    ville = random.choice(villes)
    message = {"ville": ville, "t": round(random.uniform(5,35),1), "ts": int(time.time()*1000)}
    producer.produce("temperatures", key=ville, value=json.dumps(message))
    producer.flush()
    time.sleep(0.2)  # vitesse adapt√©e



CREATE STREAM S_TEMPS_RAW1 (
  ville STRING,
  t DOUBLE,
  ts BIGINT
) WITH (
  KAFKA_TOPIC='temperatures',
  VALUE_FORMAT='JSON',
  TIMESTAMP='ts'
);

"pir verofoer la creation j'ai tap√© 
SHOW STREAMS;
et j'ai vu le s_temps_raw1

et pour visualiser j'ai tap√©

SELECT * FROM S_TEMPS_RAW1 EMIT CHANGES;

pour voir les enregistrements de la ville paris, j'ai tap√©


## photo

SELECT * FROM S_TEMPS_RAW1 WHERE ville='Paris' EMIT CHANGES;

pour tout reafficher, on peut utiliser la commande

SELECT * FROM S_TEMPS_RAW
EMIT CHANGES
LIMIT 1000;


j'ai cr√©√© un stream partitionn√© par ville (S_TEMPS_BY_VILLE)

CREATE STREAM S_TEMPS_BY_VILLE
WITH (KAFKA_TOPIC='temperatures_by_ville', PARTITIONS=4)
AS
SELECT ville, t, ts
FROM S_TEMPS_RAW1
PARTITION BY ville
EMIT CHANGES;

pour verifier j'ai tap√© √ßa et √ßa a bien marche

SHOW STREAMS;
DESCRIBE S_TEMPS_BY_VILLE;

ET enfin Dans le Control Center ‚Üí onglet Persistent Queries.

Pourquoi S_TEMPS_BY_VILLE est persistante :

Elle lit un stream existant (S_TEMPS_RAW1)

Elle √©crit en permanence dans un autre topic (temperatures_by_ville)

Elle reste active et continue de traiter les messages en temps r√©el

üîπ Les requ√™tes persistantes sont donc ‚Äúactives‚Äù tant que ksqlDB tourne.


4) 
Creation de la table avec fen√™tre TUMBLING

CREATE TABLE T_MAX_5M AS
SELECT
  ville,
  WINDOWSTART AS w_start,
  WINDOWEND   AS w_end,
  MAX(t)      AS t_max
FROM S_TEMPS_BY_VILLE
WINDOW TUMBLING (SIZE 5 MINUTES, GRACE PERIOD 30 SECONDS)
GROUP BY ville
EMIT CHANGES;

Analyse de cette commande :

WINDOW TUMBLING (SIZE 5 MINUTES) : la table regroupe les messages par blocs de 5 minutes, non chevauchants.

GRACE PERIOD 30 SECONDS : permet d‚Äôaccepter des messages retardataires jusqu‚Äô√† 30 secondes apr√®s la fin de la fen√™tre.

MAX(t) : calcule la temp√©rature maximale dans chaque fen√™tre pour chaque ville.

GROUP BY ville : agr√©gation par ville.

EMIT CHANGES : la table est mise √† jour en temps r√©el, √† mesure que de nouveaux messages arrivent.



Que voit-on dans l‚Äôonglet "Persistent Queries" ?

Tu devrais voir une nouvelle requ√™te persistante, par exemple :

Query ID	Type	Source Stream	Sink Table	Status
CSAS_T_MAX_5M_1	PERSISTENT	S_TEMPS_BY_VILLE	T_MAX_5M	RUNNING


Explication :

Cette requ√™te est persistante car elle lit un stream (S_TEMPS_BY_VILLE) en continu et √©crit les r√©sultats dans une table (T_MAX_5M).

M√™me si de nouveaux messages arrivent dans le topic temperatures, la table se met automatiquement √† jour avec les nouvelles fen√™tres et nouveaux maximas.

La persistance vient du fait que ksqlDB garde l‚Äô√©tat de la fen√™tre et des agr√©gations en m√©moire (ou dans le changelog topic associ√©).

visualisation des valeurs max
SELECT * FROM T_MAX_5M EMIT CHANGES;

Explications :

Chaque ligne correspond √† une fen√™tre de 5 minutes.

T_MAX correspond √† la temp√©rature maximale observ√©e dans cette fen√™tre pour la ville.

D√®s qu‚Äôune nouvelle fen√™tre commence, de nouvelles lignes apparaissent.

En triant par VILLE, tu peux suivre facilement l‚Äô√©volution des maximas par ville.


5)

Cr√©ation de la table T_LAST

CREATE TABLE T_LAST AS
SELECT ville,
       LATEST_BY_OFFSET(t) AS t_last,
       LATEST_BY_OFFSET(ts) AS ts_last
FROM S_TEMPS_BY_VILLE
GROUP BY ville
EMIT CHANGES;

Explication simple :

LATEST_BY_OFFSET() r√©cup√®re la derni√®re valeur arriv√©e dans le topic pour une cl√© donn√©e (ici, la ville).

GROUP BY ville garantit que chaque ville a 1 entr√©e unique dans la table.

La table est mise √† jour √† chaque nouveau message.

La table T_LAST repr√©sente donc en temps r√©el la derni√®re temp√©rature re√ßue pour chaque ville.

‚úî M√©thode 1 : Visualiser la table en streaming

Tu lances dans ksqlDB :
SELECT * FROM T_LAST EMIT CHANGES;

M√©thode 2 : Consulter la table comme une table SQL

(Utilise sans EMIT CHANGES si tu veux juste un snapshot)
SELECT * FROM T_LAST;
Tu obtiendras une seule ligne par ville, repr√©sentant le dernier √©tat connu.



Requ√™te pour obtenir en permanence la derni√®re valeur de temp√©rature pour Lyon

Tu veux suivre en temps r√©el uniquement Lyon.
SELECT t_last, ts_last
FROM T_LAST
WHERE ville = 'Lyon'
EMIT CHANGES;

Cela te donne une sortie continue, mise √† jour d√®s qu'un nouveau message est produit pour Lyon.



# ‚úÖ **7) HOPPING Windows (option)**

Tu vas maintenant cr√©er une table qui fait une **moyenne glissante des temp√©ratures** avec :

* **Fen√™tre de 10 minutes** (SIZE)
* **Avance / saut de 2 minutes** (ADVANCE BY)

üëâ Cela signifie que **toutes les 2 minutes**, une nouvelle fen√™tre de 10 minutes est calcul√©e.
Les fen√™tres **se chevauchent**, contrairement au TUMBLING.

---

# 1Ô∏è‚É£ **Cr√©er la table T_AVG_10M_HOP2**

Dans ksqlDB (Control Center ou curl) :

```sql
CREATE TABLE T_AVG_10M_HOP2 AS
SELECT
  ville,
  WINDOWSTART AS w_start,
  WINDOWEND   AS w_end,
  AVG(t)      AS t_avg
FROM S_TEMPS_BY_VILLE
WINDOW HOPPING (SIZE 10 MINUTES, ADVANCE BY 2 MINUTES)
GROUP BY ville
EMIT CHANGES;
```

Tu devrais recevoir une r√©ponse du type :

```
Table created
```

Et un **Persistent Query** va appara√Ætre.

---

# 2Ô∏è‚É£ **Que se passe-t-il derri√®re ?**

Le serveur ksqlDB cr√©e une **query persistante** qui :

* lit en continu le stream `S_TEMPS_BY_VILLE`
* calcule des fen√™tres qui se chevauchent
* cr√©e diff√©rentes entr√©es dans la table selon les fen√™tres actives

---

# 3Ô∏è‚É£ **Visualiser l‚Äô√©volution de la table**

Ex√©cute :

```sql
SELECT * FROM T_AVG_10M_HOP2 EMIT CHANGES;
```

Tu vas voir des lignes comme :

| VILLE | W_START  | W_END    | T_AVG |
| ----- | -------- | -------- | ----- |
| Paris | 21:00:00 | 21:10:00 | 23.5  |
| Paris | 21:02:00 | 21:12:00 | 24.1  |
| Paris | 21:04:00 | 21:14:00 | 22.8  |
| Lyon  | 21:00:00 | 21:10:00 | 19.4  |

üëâ Tu remarques que *pour une m√™me ville*, plusieurs fen√™tres actives existent **en m√™me temps**.

---

# 4Ô∏è‚É£ **Explication √† mettre dans ton rapport**

Voici une explication simple et propre :

> La fen√™tre HOPPING est une fen√™tre glissante avec chevauchement.
>
> * La dur√©e totale de la fen√™tre est de 10 minutes.
> * Une nouvelle fen√™tre commence toutes les 2 minutes, ce qui cr√©e plusieurs fen√™tres simultan√©es.
>   √Ä chaque nouveau message, toutes les fen√™tres qui couvrent ce timestamp sont mises √† jour.
>   La table T_AVG_10M_HOP2 stocke alors plusieurs lignes par ville, chacune correspondant √† une fen√™tre diff√©rente.

---

# 5Ô∏è‚É£ **Comment montrer l‚Äô√©volution ?**

Pendant que ton producer envoie des donn√©es, tu observes :

```sql
SELECT * FROM T_AVG_10M_HOP2 EMIT CHANGES;
```

Puis trier dans l‚Äôinterface par ville, w_start, w_end.

Tu verras les moyennes √©voluer comme :

```
Paris | 21:00:00 | 21:10:00 | 23.5
Paris | 21:02:00 | 21:12:00 | 24.1
Paris | 21:04:00 | 21:14:00 | 22.8
```

üëâ Chaque nouvelle valeur met √† jour toutes les fen√™tres o√π elle appartient.

